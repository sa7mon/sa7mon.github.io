<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Cursor on Dan [the] Salmon</title><link>https://danthesalmon.com/links/tags/cursor/</link><description>Recent content in Cursor on Dan [the] Salmon</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Wed, 10 Sep 2025 01:26:03 +0000</lastBuildDate><atom:link href="https://danthesalmon.com/links/tags/cursor/index.xml" rel="self" type="application/rss+xml"/><item><title>Wrap Up: The Month of AI Bugs</title><link>https://danthesalmon.com/links/2025-09-10_wrap-up-the-month-of-ai-bugs_2025-08-30/</link><pubDate>Wed, 10 Sep 2025 01:26:03 +0000</pubDate><guid>https://danthesalmon.com/links/2025-09-10_wrap-up-the-month-of-ai-bugs_2025-08-30/</guid><description>&lt;p>&lt;a href="https://embracethered.com/blog/posts/2025/wrapping-up-month-of-ai-bugs/">https://embracethered.com/blog/posts/2025/wrapping-up-month-of-ai-bugs/&lt;/a>
This a fantastic collection of vulnerabilities found in AI tools. I will definitely be referring to these write-ups the next time I have an LLM app to pentest.&lt;/p></description></item></channel></rss>